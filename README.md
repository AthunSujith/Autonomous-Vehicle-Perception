# ğŸš˜ Autonomous Vehicle Perception with YOLOv8  

This project builds a **YOLOv8-based perception system** using the **KITTI dataset**.  
It can detect **cars, pedestrians, and cyclists** in images, videos, and live streams.  

---

## ğŸ“‚ Project Structure
```
Autonomous-Vehicle-Perception/
â”‚
â”œâ”€â”€ data/                       # Dataset folder (processed in YOLO format)
â”‚   â”œâ”€â”€ raw/                    # Original KITTI dataset
â”‚   â”œâ”€â”€ processed/              # YOLO-ready data
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â””â”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ labels/
â”‚   â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â””â”€â”€ val/
â”‚   â”‚   â””â”€â”€ kitti.yaml          # Dataset config for YOLO
â”‚
â”œâ”€â”€ runs/                       # YOLO training outputs (weights, logs, results)
â”‚
â”œâ”€â”€ prepare_data.py             # Convert KITTI â†’ YOLO format
â”œâ”€â”€ register_coco_dataset.py    # Register dataset for COCO-style evaluation
â”œâ”€â”€ utils.py                    # Helper functions (dataset checks, stats)
â”œâ”€â”€ demo_notebook.ipynb         # Step-by-step training & inference notebook
â”œâ”€â”€ app_media_mode.py           # Streamlit app (image/video/live detection)
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # Project documentation
```

---

## ğŸ“Š Dataset Source
- We use the **[KITTI Vision Benchmark Suite](http://www.cvlibs.net/datasets/kitti/)**.  
- Classes included:  
  - ğŸš— Car  
  - ğŸš¶ Pedestrian  
  - ğŸš´ Cyclist  

---

## âš™ï¸ Training the Model  

1ï¸âƒ£ **Install dependencies**  
```bash
pip install -r requirements.txt
```

2ï¸âƒ£ **Prepare dataset (convert KITTI â†’ YOLO format)**  
```bash
python prepare_data.py
```

3ï¸âƒ£ **Train YOLOv8**  
```bash
yolo task=detect mode=train model=yolov8n.pt data=data/processed/kitti.yaml epochs=50 imgsz=640 batch=16 device=0
```

4ï¸âƒ£ **Export trained model (optional)**  
```bash
yolo export model=runs/detect/train/weights/best.pt format=onnx
```

---

## ğŸš€ Running the Demo App  

1ï¸âƒ£ Run Streamlit app:  
```bash
streamlit run app_media_mode.py
```

2ï¸âƒ£ Choose input mode in UI:  
- ğŸ–¼ Upload Image â†’ detect cars, pedestrians, cyclists.  
- ğŸ Upload Video â†’ run detection frame-by-frame.  
- ğŸ“· Live Webcam â†’ real-time detection.  

---

## ğŸ“ˆ Results & Use-Cases
- Detects **objects in driving scenes** from KITTI dataset.  
- Useful for:  
  - Autonomous driving research.  
  - Traffic surveillance.  
  - Pedestrian safety systems.  

---

âœ… With this setup, you can **train, evaluate, and deploy** a computer vision system for self-driving cars in one project.  
